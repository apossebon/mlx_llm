#!/usr/bin/env python3
"""
Modo Agent com execuÃ§Ã£o real de ferramentas
Implementa um loop completo de conversaÃ§Ã£o com execuÃ§Ã£o automÃ¡tica de tools
"""

import sys
import json
from typing import List, Dict, Any, Optional
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from chatmlx import ChatMLX


class MLXAgent:
    """
    Agent que usa ChatMLX com execuÃ§Ã£o automÃ¡tica de ferramentas
    """
    
    def __init__(self, model_name: Optional[str] = None):
        """
        Inicializa o agent com ChatMLX
        
        Args:
            model_name: Nome do modelo MLX a usar (opcional)
        """
        # Usar modelo padrÃ£o se nÃ£o especificado
        if model_name is None:
            model_name = "lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-4bit"
        
        self.llm = ChatMLX(model_name=model_name)
        self.llm.init()
        self.tools = {}
        self.conversation_history = []
        
    def add_tool(self, tool_func):
        """
        Adiciona uma ferramenta ao agent
        
        Args:
            tool_func: FunÃ§Ã£o decorada com @tool do LangChain
        """
        self.tools[tool_func.name] = tool_func
        
    def bind_tools(self, tools: List):
        """
        Vincula mÃºltiplas ferramentas ao agent
        
        Args:
            tools: Lista de funÃ§Ãµes decoradas com @tool
        """
        for tool_func in tools:
            self.add_tool(tool_func)
        
        # Vincular ferramentas ao modelo LLM
        self.llm_with_tools = self.llm.bind_tools(tools)
        self.llm_with_tools.init()
        
    def execute_tool(self, tool_call: Dict) -> str:
        """
        Executa uma ferramenta especÃ­fica
        
        Args:
            tool_call: DicionÃ¡rio com informaÃ§Ãµes da tool call
            
        Returns:
            Resultado da execuÃ§Ã£o da ferramenta
        """
        tool_name = tool_call.get("name")
        tool_args = tool_call.get("args", {})
        
        if tool_name not in self.tools:
            return f"âŒ Ferramenta '{tool_name}' nÃ£o encontrada!"
        
        try:
            # Executar a ferramenta
            tool_func = self.tools[tool_name]
            result = tool_func.invoke(tool_args)
            
            print(f"ğŸ”§ Executando {tool_name}({tool_args}) â†’ {result}")
            return str(result)
            
        except Exception as e:
            error_msg = f"âŒ Erro ao executar {tool_name}: {str(e)}"
            print(error_msg)
            return error_msg
    
    def chat(self, user_message: str, max_iterations: int = 5) -> str:
        """
        Processa uma mensagem do usuÃ¡rio com execuÃ§Ã£o automÃ¡tica de ferramentas
        
        Args:
            user_message: Mensagem do usuÃ¡rio
            max_iterations: MÃ¡ximo de iteraÃ§Ãµes para evitar loops infinitos
            
        Returns:
            Resposta final do agent
        """
        print(f"\nğŸ‘¤ UsuÃ¡rio: {user_message}")
        
        # Adicionar mensagem do usuÃ¡rio ao histÃ³rico
        messages = self.conversation_history + [HumanMessage(content=user_message)]
        
        iteration = 0
        while iteration < max_iterations:
            iteration += 1
            print(f"\nğŸ”„ IteraÃ§Ã£o {iteration}")
            
            # Gerar resposta do modelo
            try:
                response = self.llm_with_tools.invoke(messages)
                print(f"ğŸ¤– Modelo: {response.content}")
                
                # Verificar se hÃ¡ tool calls
                if response.tool_calls:
                    print(f"ğŸ”§ Tool calls detectados: {len(response.tool_calls)}")
                    
                    # Adicionar resposta do modelo ao histÃ³rico
                    messages.append(response)
                    
                    # Executar cada tool call
                    for i, tool_call in enumerate(response.tool_calls):
                        print(f"\nğŸ”§ Executando Tool Call {i+1}:")
                        print(f"   Nome: {tool_call.get('name')}")
                        print(f"   Args: {tool_call.get('args')}")
                        
                        # Executar ferramenta
                        tool_result = self.execute_tool(tool_call)
                        
                        # Criar ToolMessage com o resultado
                        tool_message = ToolMessage(
                            content=tool_result,
                            tool_call_id=tool_call.get("id"),
                            name=tool_call.get("name")
                        )
                        
                        # Adicionar resultado ao histÃ³rico
                        messages.append(tool_message)
                    
                    # Continuar o loop para gerar resposta final
                    continue
                
                else:
                    # Sem tool calls - resposta final
                    print(f"âœ… Resposta final: {response.content}")
                    
                    # Atualizar histÃ³rico da conversa
                    self.conversation_history = messages + [response]
                    
                    return response.content
                    
            except Exception as e:
                error_msg = f"âŒ Erro na iteraÃ§Ã£o {iteration}: {str(e)}"
                print(error_msg)
                return error_msg
        
        # Se chegou ao limite de iteraÃ§Ãµes
        final_msg = f"âš ï¸ Limite de {max_iterations} iteraÃ§Ãµes atingido"
        print(final_msg)
        return final_msg
    
    def reset_conversation(self):
        """
        Limpa o histÃ³rico da conversa
        """
        self.conversation_history = []
        print("ğŸ”„ HistÃ³rico da conversa limpo")
    
    def show_conversation_history(self):
        """
        Mostra o histÃ³rico da conversa
        """
        print("\nğŸ“œ HistÃ³rico da Conversa:")
        print("=" * 50)
        
        for i, msg in enumerate(self.conversation_history):
            if isinstance(msg, HumanMessage):
                print(f"{i+1}. ğŸ‘¤ UsuÃ¡rio: {msg.content}")
            elif isinstance(msg, AIMessage):
                print(f"{i+1}. ğŸ¤– Assistant: {msg.content}")
                if msg.tool_calls:
                    print(f"   ğŸ”§ Tool calls: {len(msg.tool_calls)}")
            elif isinstance(msg, ToolMessage):
                print(f"{i+1}. ğŸ”§ Tool '{msg.name}': {msg.content}")
        
        print("=" * 50)


# Ferramentas de exemplo
@tool
def get_weather(location: str) -> str:
    """ObtÃ©m informaÃ§Ãµes do clima para uma localizaÃ§Ã£o."""
    # SimulaÃ§Ã£o de API de clima
    weather_data = {
        "SÃ£o Paulo": "Ensolarado, 25Â°C",
        "Rio de Janeiro": "Parcialmente nublado, 28Â°C", 
        "San Francisco": "Nublado, 18Â°C",
        "New York": "Chuva leve, 15Â°C",
        "London": "Nublado, 12Â°C"
    }
    
    location_clean = location.strip().title()
    
    # Buscar por correspondÃªncia parcial
    for city, weather in weather_data.items():
        if location_clean.lower() in city.lower() or city.lower() in location_clean.lower():
            return f"ğŸŒ¤ï¸ Clima em {city}: {weather}"
    
    # Se nÃ£o encontrou, retornar clima genÃ©rico
    return f"ğŸŒ¤ï¸ Clima em {location}: Ensolarado, 22Â°C (dados simulados)"


@tool  
def search_web(query: str) -> str:
    """Busca informaÃ§Ãµes na web sobre um tÃ³pico."""
    # SimulaÃ§Ã£o de busca web
    search_results = {
        "python": "Python Ã© uma linguagem de programaÃ§Ã£o de alto nÃ­vel, interpretada e de propÃ³sito geral.",
        "machine learning": "Machine Learning Ã© um subcampo da IA que permite aos computadores aprender sem serem explicitamente programados.",
        "langchain": "LangChain Ã© um framework para desenvolvimento de aplicaÃ§Ãµes com modelos de linguagem.",
        "mlx": "MLX Ã© um framework de machine learning para Apple Silicon desenvolvido pela Apple."
    }
    
    query_lower = query.lower()
    
    # Buscar por correspondÃªncia parcial
    for topic, info in search_results.items():
        if topic in query_lower or any(word in query_lower for word in topic.split()):
            return f"ğŸ” InformaÃ§Ãµes sobre '{topic}': {info}"
    
    # Resultado genÃ©rico se nÃ£o encontrou
    return f"ğŸ” Resultados para '{query}': InformaÃ§Ãµes encontradas sobre o tÃ³pico solicitado (simulado)"


@tool
def calculate(expression: str) -> str:
    """Calcula expressÃµes matemÃ¡ticas simples."""
    try:
        # Avaliar expressÃ£o matemÃ¡tica de forma segura
        # Remover espaÃ§os e caracteres nÃ£o permitidos
        safe_expr = expression.replace(" ", "")
        
        # Lista de caracteres permitidos
        allowed_chars = "0123456789+-*/.()%"
        if not all(c in allowed_chars for c in safe_expr):
            return "âŒ ExpressÃ£o contÃ©m caracteres nÃ£o permitidos"
        
        # Calcular
        result = eval(safe_expr)
        return f"ğŸ§® {expression} = {result}"
        
    except Exception as e:
        return f"âŒ Erro no cÃ¡lculo: {str(e)}"


def main():
    """
    FunÃ§Ã£o principal para demonstrar o agent
    """
    print("ğŸ¤– MLX Agent - Modo Interativo")
    print("=" * 50)
    
    # Criar agent
    agent = MLXAgent()
    
    # Adicionar ferramentas
    agent.bind_tools([get_weather, search_web, calculate])
    
    print("âœ… Agent inicializado com ferramentas:")
    print("   ğŸŒ¤ï¸  get_weather - InformaÃ§Ãµes do clima")
    print("   ğŸ” search_web - Busca na web") 
    print("   ğŸ§® calculate - Calculadora")
    print("\nğŸ’¡ Digite 'quit' para sair, 'history' para ver histÃ³rico, 'reset' para limpar")
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ VocÃª: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'sair']:
                print("ğŸ‘‹ AtÃ© logo!")
                break
            elif user_input.lower() in ['history', 'histÃ³rico']:
                agent.show_conversation_history()
                continue
            elif user_input.lower() == 'reset':
                agent.reset_conversation()
                continue
            elif not user_input:
                continue
            
            # Processar mensagem
            response = agent.chat(user_input)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ AtÃ© logo!")
            break
        except Exception as e:
            print(f"âŒ Erro: {e}")


if __name__ == "__main__":
    main()
